{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Librerias"
      ],
      "metadata": {
        "id": "Lipo7631hyAp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SAsBFn-ahH8Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans as km\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.datasets import make_blobs\n",
        "import random\n",
        "from sklearn.metrics import adjusted_rand_score as ari\n",
        "from sklearn.metrics import completeness_score as completitud\n",
        "from sklearn.metrics import fowlkes_mallows_score as FM\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import copy\n",
        "from sklearn.metrics import davies_bouldin_score as DB\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CÃ³digo PSOkmeans"
      ],
      "metadata": {
        "id": "Q4qdKpI2h0NB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class particula:\n",
        "  def __init__(self, d : int, x_min : float, x_max : float,\n",
        "               v_min : float, v_max: float, k, centros):\n",
        "    self.posicion = centros\n",
        "    self.velocidad = np.random.uniform(v_min,v_max,size = (k,d))\n",
        "    self.aptitud = None\n",
        "    self.mejorPos = copy.deepcopy(self.posicion)\n",
        "    self.apt_best = None\n",
        "    self.nGrupos = k\n",
        "    self.dim = d\n",
        "    self.labels_ = None"
      ],
      "metadata": {
        "id": "RoIuFZK8hNEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aptitud(particula, datos):\n",
        "  '''Asigna el valor de la aptitud a una particula en\n",
        "  base a su particion y centroides '''\n",
        "  #calculamos la aptitud\n",
        "  separacion = 0\n",
        "  for i,centro in enumerate(particula.posicion):\n",
        "    #obtenemos los elementos del grupo i\n",
        "    elementos = datos[np.where(particula.labels_ == i)]\n",
        "    separacion+=sum(\n",
        "        [np.linalg.norm(dato-centro)**2 for dato in elementos])\n",
        "  return(separacion/len(datos))"
      ],
      "metadata": {
        "id": "-DaHrPoniN5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aptitud2(particula,datos):\n",
        "  return(DB(datos,particula.labels_))"
      ],
      "metadata": {
        "id": "Immvvbfu68vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iniciar(x_min,x_max,v_min,v_max,k,n_part,datos,f_apt):\n",
        "  '''d es la dimension de los datos\n",
        "  x_max y x_min delimitan el intervalo de los valores de los datos'''\n",
        "  dim = len(datos[0])\n",
        "  particulas= []\n",
        "  for i in range(n_part):\n",
        "    centros = np.array(random.choices(datos,k=k))\n",
        "    part = particula(dim,x_min,x_max,v_max,v_min,k,centros)\n",
        "    verificar_posicion(part,x_min,x_max,datos)\n",
        "    part.aptitud = f_apt(part,datos)\n",
        "    part.apt_best = copy.deepcopy(part.aptitud)\n",
        "    particulas.append(part)\n",
        "  mejor = copy.deepcopy(min(particulas, key=lambda x: x.aptitud))\n",
        "  return(particulas,mejor)"
      ],
      "metadata": {
        "id": "d5xhxZUbjOKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mover_part(part,inercia,mejor_pos,c1,c2,x_min,x_max,v_min,v_max):\n",
        "  r1,r2 = np.random.uniform(0,1,2)\n",
        "  velocidad = inercia*part.velocidad+(c1*r1*(part.mejorPos-part.posicion))+(c2*r2*(mejor_pos-part.posicion))\n",
        "  posicion = part.posicion + velocidad\n",
        "  #revisar velocidad este dentro del rango\n",
        "  velocidad[np.where(velocidad<v_min)] = v_min\n",
        "  velocidad[np.where(velocidad>v_max)] = v_max\n",
        "  return(velocidad,posicion)"
      ],
      "metadata": {
        "id": "4zQsdXn1y5LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verificar_posicion(particula,x_min,x_max, datos):\n",
        "  ''' esta funcion verifica que los centroides no se salgan del rango del\n",
        "  problema en cuestion, se considera que un centroide esta fuera de rango\n",
        "  cuando (1): sus componentes salen del minimo o maximo valor permitido\n",
        "  o (2): cuando el centroide no tienen ningun dato asignado'''\n",
        "  for i,pos in enumerate(particula.posicion):\n",
        "    #comprobamos si algun valor se sale de su x_min o de su x_max\n",
        "    if np.where(pos<x_min)[0].size >0 or np.where(pos>x_max)[0].size >0:\n",
        "      particula.posicion[i] = random.choice(datos)\n",
        "  cambios = True\n",
        "  while cambios:\n",
        "    distancias  = euclidean_distances(datos,particula.posicion)\n",
        "    etiquetas = np.argmin(distancias, axis = 1).tolist()\n",
        "    cambios = False\n",
        "    for i in range(particula.nGrupos):\n",
        "      if etiquetas.count(i) == 0:\n",
        "        particula.posicion[i] = random.choice(datos)\n",
        "        cambios = True\n",
        "  particula.labels_ = np.array(etiquetas)"
      ],
      "metadata": {
        "id": "W251xs3-EJcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pso(x_min,x_max,v_min,v_max,k,n_part,iter_pso,iter_kmean,c1,c2,datos,f_apt):\n",
        "  '''n_part es el numero de particulas\n",
        "  k es el numero de grupos a hacer\n",
        "  x_min y x_max son vectores con los minimos y maximos valores\n",
        "  de cada componente en los datos'''\n",
        "  enjambre,mejor_inicial = iniciar(x_min=x_min,x_max=x_max,\n",
        "                                   v_min=v_min,v_max=v_max,k=k,\n",
        "                                   n_part=n_part, datos=datos,f_apt=f_apt)\n",
        "  cont = 0; sin_cambios = 0; inercia = 0.6; dism = 0.5/(iter_pso-1)\n",
        "  while True:\n",
        "    if cont == iter_pso:\n",
        "      break\n",
        "    for part in enjambre: #actualizar posicion y velocidad\n",
        "      part.velocidad,part.posicion = mover_part(part=part,inercia=inercia,\n",
        "                                 mejor_pos = mejor_inicial.posicion,\n",
        "                                 c1=c1, c2=c2, x_min=x_min, x_max=x_max,\n",
        "                                 v_min=v_min, v_max=v_max)\n",
        "      verificar_posicion(part,x_min,x_max,datos)\n",
        "      part.aptitud = f_apt(part,datos)\n",
        "      #verificamos la mejor posicion visitada de la particula\n",
        "      if part.aptitud < part.apt_best:\n",
        "        part.apt_best = copy.copy(part.aptitud)\n",
        "        part.mejorPos = copy.copy(part.posicion)\n",
        "    #obtener mejor posicion de la iteracion\n",
        "    mejor_final = copy.deepcopy(min(enjambre, key= lambda x: x.aptitud))\n",
        "    #inercia = inercia - dism\n",
        "    cont += 1\n",
        "    if mejor_final.aptitud < mejor_inicial.aptitud:\n",
        "      mejor_inicial = copy.deepcopy(mejor_final)\n",
        "      sin_cambios = 0\n",
        "    else:\n",
        "      sin_cambios += 1\n",
        "    if sin_cambios == 10:\n",
        "      break\n",
        "  #ejecutamos kmeans\n",
        "  reskmeans = km(n_clusters=k,n_init=1,\n",
        "              max_iter=iter_kmean,init=mejor_inicial.posicion).fit(datos)\n",
        "  reskmeans.posicion = reskmeans.cluster_centers_\n",
        "  reskmeans.aptitud = f_apt(reskmeans,datos)\n",
        "  return(reskmeans)"
      ],
      "metadata": {
        "id": "CaDqMvJ7ifDD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}